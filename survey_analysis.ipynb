{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f173a9ae-bcbb-4190-b702-aac15e1363f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204ad1b-fdde-4cd0-9d74-bc33f99a28c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loading\n",
    "Loading EPA's Smart Location Database <br>\n",
    "Loading survey data from Baltimore Ecosystem Study <br>\n",
    "Merging the two data sources on Census Block Group (GEOID10). This removes many of the rows from the SLD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052a79a9-cbf2-4857-ac09-8795e4245570",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_data = gpd.read_file('data/SmartLocationDatabaseV3/SmartLocationDatabase.gdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140c5c55-708a-42f3-ad58-346285f94c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data = pd.read_csv('data/survey/BESTS_1999_2000_2003_2006_2011_ANON.csv', low_memory=False)\n",
    "# GEOID_2010 seems to be corrupted (have missing information) for some cities\n",
    "survey_data = survey_data.drop(labels='GEOID_2010', axis=1)\n",
    "survey_data.GISJOIN_2010 = survey_data.GISJOIN_2010.astype('str')\n",
    "survey_data.GISJOIN_2010 = survey_data.GISJOIN_2010.apply(lambda x: x[1:3]+x[4:7]+x[8:])\n",
    "# Rename GISJOIN_2010 to GEOID10 to match SLD\n",
    "survey_data = survey_data.rename({'GISJOIN_2010':'GEOID10'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3e367f-a827-48e2-80a1-f882967cdbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 14298\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(survey_data, sl_data, on='GEOID10')\n",
    "print('Number of samples:',len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc5e2e8-3386-4356-9593-8725df138698",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb4578c-1b03-471a-9aa9-00c1b28e9f73",
   "metadata": {},
   "source": [
    "Adding in covariates for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ecafea4-2aa4-4dff-83b9-95772bc422e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex: Female is 1, Male is 0\n",
    "df['sex_code'] = pd.Series(np.zeros(len(df)))\n",
    "df.loc[df.sex=='male','sex_code'] = 0\n",
    "df.loc[df.sex=='female','sex_code'] = 1\n",
    "\n",
    "# Race: different column for each race category in the survey data\n",
    "df['black_code'] = pd.Series(np.zeros(len(df)))\n",
    "df.loc[df.race=='black','black_code'] = 1\n",
    "df['hispanic_code'] = pd.Series(np.zeros(len(df)))\n",
    "df.loc[df.race=='hispanic','hispanic_code'] = 1\n",
    "df['white_code'] = pd.Series(np.zeros(len(df)))\n",
    "df.loc[df.race=='white','white_code'] = 1\n",
    "df['asian_code'] = pd.Series(np.zeros(len(df)))\n",
    "df.loc[df.race=='asian','asian_code'] = 1\n",
    "\n",
    "# Age and Education level: recode as floats\n",
    "df.age = df.age.replace('dk refused', np.nan)\n",
    "df.age = df.age.astype('float')\n",
    "df.edu = df.edu.replace('dk refused', np.nan)\n",
    "df.edu = df.edu.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d6b9ac-34ae-4194-bc68-417ee29a2a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode income categories to integers (increasing with increased income)\n",
    "def income_to_value(row):\n",
    "    val = np.NaN\n",
    "    if row.income2 == 'refused': val = 0\n",
    "    if row.income2 == 'under $15K': val = 0\n",
    "    if row.income2 == '$15K to $25K': val = 1\n",
    "    if row.income2 == '$25K to $35K': val = 2\n",
    "    if row.income2 == '$35K to $50K': val = 3\n",
    "    if row.income2 == '$50K to $75K': val = 4\n",
    "    if row.income2 == '$75K to $100K': val = 5\n",
    "    if row.income2 == 'over $100K': val = 6\n",
    "    return val\n",
    "df['Income_Value'] = df.apply(income_to_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab577ec-831f-4313-b3bd-de2fe5c522f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add city string based on the state number in the SLD\n",
    "# Note: this workaround only works because each analyzed city is in a different state\n",
    "df['State_Number'] = df.GEOID10.apply(lambda x: x[:2])\n",
    "def state_to_city(row):\n",
    "    city = np.NaN\n",
    "    if row.State_Number == '25' or row.State_Number == '33': city = 'Boston' # Boston\n",
    "    if row.State_Number == '24': city = 'Baltimore' # Baltimore\n",
    "    if row.State_Number == '27': city = 'Twin_Cities' # Twin Cities\n",
    "    if row.State_Number == '12': city = 'Orlando' # Orlando\n",
    "    if row.State_Number == '04': city = 'Phoenix' # Phoenix\n",
    "    if row.State_Number == '06': city = 'LA' # LA\n",
    "    return city\n",
    "df['City'] = df.apply(state_to_city, axis=1)\n",
    "city_hot = pd.get_dummies(df['City'])\n",
    "df = df.join(city_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403bf392-d2ea-4409-9494-bc28a7f9d67e",
   "metadata": {},
   "source": [
    "## Finalize dataset for SEM analysis and save to file\n",
    "SEM analysis completed in `R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0656e52-2c36-43c1-a4c0-4db8404fcad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations with NAs: 14298\n",
      "Number of observations without NAs: 9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/opt/miniconda3/envs/walkability/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/andrew/opt/miniconda3/envs/walkability/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "sem_data = pd.DataFrame()\n",
    "# Cohesion data\n",
    "sem_data[['Close_Knit','Trust','Known_Neighs','Will_Help']] = df[['closeKnit','trust','knownNeighs','willHelp']]\n",
    "# Diversity of built environment data\n",
    "sem_data[['Emp_HH_Entropy','Emp_Entropy']] = df[['D2A_EPHHM','D2B_E8MIXA']] # both pretty normal\n",
    "# Physical density data\n",
    "sem_data[['Intersection_Density','Path_Density']] = df[['D3B','D3APO']]\n",
    "# Social density data\n",
    "sem_data[['HH_Density','Pop_Density','Emp_Density']] = df[['D1A','D1B','D1C']]\n",
    "# Neighborhood connectedness data\n",
    "sem_data[['Transit_Dist','Transit_Service']] = df[['D4A','D4D']]\n",
    "# Covariates\n",
    "sem_data[['Age','Sex','Education','Income','White','Black','Hispanic','Asian','City']] = df[['age','sex_code','edu','Income_Value','white_code','black_code','hispanic_code','asian_code','City']]\n",
    "\n",
    "# Necessary Transformations\n",
    "sem_data.Transit_Dist[sem_data.Transit_Dist==-99999] = 1500\n",
    "sem_data.Transit_Service[sem_data.Transit_Service==-99999] = 0\n",
    "sem_data['Transit_Proximity'] = -sem_data['Transit_Dist']\n",
    "\n",
    "# Include year for validation of time differences\n",
    "sem_data[['Year']] = df[['year']]\n",
    "\n",
    "print('Number of observations with NAs:',len(sem_data))\n",
    "sem_data = sem_data.dropna()\n",
    "print('Number of observations without NAs:',len(sem_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ce786cb-16fa-4e40-90e6-918c6759773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_data.to_csv('sem_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f7f7895-8b3a-429c-a2e6-37aed199c0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_Knit</th>\n",
       "      <th>Trust</th>\n",
       "      <th>Known_Neighs</th>\n",
       "      <th>Will_Help</th>\n",
       "      <th>Emp_HH_Entropy</th>\n",
       "      <th>Emp_Entropy</th>\n",
       "      <th>Intersection_Density</th>\n",
       "      <th>Path_Density</th>\n",
       "      <th>HH_Density</th>\n",
       "      <th>Pop_Density</th>\n",
       "      <th>...</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Asian</th>\n",
       "      <th>City</th>\n",
       "      <th>Transit_Proximity</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.752846</td>\n",
       "      <td>0.676656</td>\n",
       "      <td>260.751487</td>\n",
       "      <td>17.631891</td>\n",
       "      <td>20.852711</td>\n",
       "      <td>30.149391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>-131.43</td>\n",
       "      <td>2,006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.752846</td>\n",
       "      <td>0.676656</td>\n",
       "      <td>260.751487</td>\n",
       "      <td>17.631891</td>\n",
       "      <td>20.852711</td>\n",
       "      <td>30.149391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>-131.43</td>\n",
       "      <td>2,006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.752846</td>\n",
       "      <td>0.676656</td>\n",
       "      <td>260.751487</td>\n",
       "      <td>17.631891</td>\n",
       "      <td>20.852711</td>\n",
       "      <td>30.149391</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>-131.43</td>\n",
       "      <td>2,006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.703732</td>\n",
       "      <td>0.565168</td>\n",
       "      <td>440.711629</td>\n",
       "      <td>25.097283</td>\n",
       "      <td>13.713280</td>\n",
       "      <td>30.395414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>-264.20</td>\n",
       "      <td>2,006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.259635</td>\n",
       "      <td>0.433318</td>\n",
       "      <td>90.965554</td>\n",
       "      <td>18.028975</td>\n",
       "      <td>5.475670</td>\n",
       "      <td>14.239056</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>-445.25</td>\n",
       "      <td>2,006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Close_Knit  Trust  Known_Neighs  Will_Help  Emp_HH_Entropy  Emp_Entropy  \\\n",
       "7          4.0    4.0           2.0        4.0        0.752846     0.676656   \n",
       "8          3.0    5.0           4.0        5.0        0.752846     0.676656   \n",
       "10         4.0    4.0           2.0        4.0        0.752846     0.676656   \n",
       "13         3.0    3.0           4.0        3.0        0.703732     0.565168   \n",
       "16         4.0    4.0           2.0        4.0        0.259635     0.433318   \n",
       "\n",
       "    Intersection_Density  Path_Density  HH_Density  Pop_Density  ...  Sex  \\\n",
       "7             260.751487     17.631891   20.852711    30.149391  ...  1.0   \n",
       "8             260.751487     17.631891   20.852711    30.149391  ...  0.0   \n",
       "10            260.751487     17.631891   20.852711    30.149391  ...  1.0   \n",
       "13            440.711629     25.097283   13.713280    30.395414  ...  0.0   \n",
       "16             90.965554     18.028975    5.475670    14.239056  ...  1.0   \n",
       "\n",
       "    Education  Income  White  Black  Hispanic  Asian       City  \\\n",
       "7         4.0     5.0    1.0    0.0       0.0    0.0  Baltimore   \n",
       "8         5.0     5.0    1.0    0.0       0.0    0.0  Baltimore   \n",
       "10        5.0     6.0    1.0    0.0       0.0    0.0  Baltimore   \n",
       "13        4.0     6.0    1.0    0.0       0.0    0.0  Baltimore   \n",
       "16        5.0     6.0    0.0    1.0       0.0    0.0  Baltimore   \n",
       "\n",
       "    Transit_Proximity   Year  \n",
       "7             -131.43  2,006  \n",
       "8             -131.43  2,006  \n",
       "10            -131.43  2,006  \n",
       "13            -264.20  2,006  \n",
       "16            -445.25  2,006  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cecfad9c-02e8-49f9-9fce-b5ba87d69aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of data from 2006: , 0.2642192347466391\n",
      "Percentage of data from 2011: , 0.7357807652533609\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of data from 2006: ,\", sum(sem_data.Year=='2,006') / (sum(sem_data.Year=='2,006') + sum(sem_data.Year=='2,011')))\n",
    "print(\"Proportion of data from 2011: ,\", sum(sem_data.Year=='2,011') / (sum(sem_data.Year=='2,006') + sum(sem_data.Year=='2,011')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b10479-f06a-4777-aca0-7754786562fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "walkability",
   "language": "python",
   "name": "walkability"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
